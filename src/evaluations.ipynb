{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare fused results based on three different prompt strategies with the baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LaTeX table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ranx import Qrels, Run, evaluate, compare\n",
    "import pandas as pd\n",
    "\n",
    "# https://ir-datasets.com/nyt.html  \n",
    "qrels = Qrels.from_ir_datasets(\"nyt/trec-core-2017\")\n",
    "track = 'core17'\n",
    "num_topics = 50\n",
    "\n",
    "run_bm25 = Run.from_file('../runs/baselines/' + track + '.BM25.lz4', kind='lz4')\n",
    "run_bm25.name = 'BM25'\n",
    "run_bm25_rm3 = Run.from_file('../runs/baselines/' + track + '.BM25+RM3.lz4', kind='lz4')\n",
    "run_bm25_rm3.name = 'BM25+RM3'\n",
    "run_rrf_1 = Run.from_file('../runs/gpt-4o/' + track + '.10.rrf.P-1.lz4', kind='lz4')\n",
    "run_rrf_1.name = 'P-1'\n",
    "run_rrf_2 = Run.from_file('../runs/gpt-4o/' + track + '.10.rrf.P-2.lz4', kind='lz4')\n",
    "run_rrf_2.name = 'P-2'\n",
    "run_rrf_3 = Run.from_file('../runs/gpt-4o/' + track + '.10.rrf.P-3.lz4', kind='lz4')\n",
    "run_rrf_3.name = 'P-3'\n",
    "\n",
    "runs = [\n",
    "          run_bm25,\n",
    "          run_bm25_rm3,\n",
    "          run_rrf_1,\n",
    "          run_rrf_2,\n",
    "          run_rrf_3,\n",
    "        ]\n",
    "\n",
    "report = compare(\n",
    "    qrels=qrels,\n",
    "    runs=runs,\n",
    "    metrics=[\"precision@10\", \"ndcg@10\", \"bpref\", \"map\"],\n",
    "    max_p=0.05 / len(runs)\n",
    ")\n",
    "\n",
    "print(report)\n",
    "print(report.to_latex())\n",
    "\n",
    "# https://ir-datasets.com/wapo.html\n",
    "qrels = Qrels.from_ir_datasets(\"wapo/v2/trec-core-2018\")\n",
    "track = 'core18'\n",
    "num_topics = 50\n",
    "\n",
    "run_bm25 = Run.from_file('../runs/baselines/' + track + '.BM25.lz4', kind='lz4')\n",
    "run_bm25.name = 'BM25'\n",
    "run_bm25_rm3 = Run.from_file('../runs/baselines/' + track + '.BM25+RM3.lz4', kind='lz4')\n",
    "run_bm25_rm3.name = 'BM25+RM3'\n",
    "run_rrf_1 = Run.from_file('../runs/gpt-4o/' + track + '.10.rrf.P-1.lz4', kind='lz4')\n",
    "run_rrf_1.name = 'P-1'\n",
    "run_rrf_2 = Run.from_file('../runs/gpt-4o/' + track + '.10.rrf.P-2.lz4', kind='lz4')\n",
    "run_rrf_2.name = 'P-2'\n",
    "run_rrf_3 = Run.from_file('../runs/gpt-4o/' + track + '.10.rrf.P-3.lz4', kind='lz4')\n",
    "run_rrf_3.name = 'P-3'\n",
    "\n",
    "runs = [\n",
    "          run_bm25,\n",
    "          run_bm25_rm3,\n",
    "          run_rrf_1,\n",
    "          run_rrf_2,\n",
    "          run_rrf_3,\n",
    "        ]\n",
    "\n",
    "report = compare(\n",
    "    qrels=qrels,\n",
    "    runs=runs,\n",
    "    metrics=[\"precision@10\", \"ndcg@10\", \"bpref\", \"map\"],\n",
    "    max_p=0.05 / len(runs)\n",
    ")\n",
    "\n",
    "print(report)\n",
    "print(report.to_latex())\n",
    "\n",
    "# https://ir-datasets.com/disks45.html \n",
    "qrels = Qrels.from_ir_datasets(\"disks45/nocr/trec-robust-2004\")\n",
    "track = 'robust04'\n",
    "num_topics = 250\n",
    "\n",
    "run_bm25 = Run.from_file('../runs/baselines/' + track + '.BM25.lz4', kind='lz4')\n",
    "run_bm25.name = 'BM25'\n",
    "run_bm25_rm3 = Run.from_file('../runs/baselines/' + track + '.BM25+RM3.lz4', kind='lz4')\n",
    "run_bm25_rm3.name = 'BM25+RM3'\n",
    "run_rrf_1 = Run.from_file('../runs/gpt-4o/' + track + '.10.rrf.P-1.lz4', kind='lz4')\n",
    "run_rrf_1.name = 'P-1'\n",
    "run_rrf_2 = Run.from_file('../runs/gpt-4o/' + track + '.10.rrf.P-2.lz4')\n",
    "run_rrf_2.name = 'P-2'\n",
    "run_rrf_3 = Run.from_file('../runs/gpt-4o/' + track + '.10.rrf.P-3.lz4', kind='lz4')\n",
    "run_rrf_3.name = 'P-3'\n",
    "\n",
    "runs = [\n",
    "          run_bm25,\n",
    "          run_bm25_rm3,\n",
    "          run_rrf_1,\n",
    "          run_rrf_2,\n",
    "          run_rrf_3,\n",
    "        ]\n",
    "\n",
    "report = compare(\n",
    "    qrels=qrels,\n",
    "    runs=runs,\n",
    "    metrics=[\"precision@10\", \"ndcg@10\", \"bpref\", \"map\"],\n",
    "    max_p=0.05 / len(runs)\n",
    ")\n",
    "\n",
    "print(report)\n",
    "print(report.to_latex())\n",
    "\n",
    "# https://ir-datasets.com/aquaint.html\n",
    "qrels = Qrels.from_ir_datasets(\"aquaint/trec-robust-2005\")\n",
    "track = 'robust05'\n",
    "num_topics = 50\n",
    "\n",
    "run_bm25 = Run.from_file('../runs/baselines/' + track + '.BM25.lz4', kind='lz4')\n",
    "run_bm25.name = 'BM25'\n",
    "run_bm25_rm3 = Run.from_file('../runs/baselines/' + track + '.BM25+RM3.lz4', kind='lz4')\n",
    "run_bm25_rm3.name = 'BM25+RM3'\n",
    "run_rrf_1 = Run.from_file('../runs/gpt-4o/' + track + '.10.rrf.P-1.lz4', kind='lz4')\n",
    "run_rrf_1.name = 'P-1'\n",
    "run_rrf_2 = Run.from_file('../runs/gpt-4o/' + track + '.10.rrf.P-2.lz4', kind='lz4')\n",
    "run_rrf_2.name = 'P-2'\n",
    "run_rrf_3 = Run.from_file('../runs/gpt-4o/' + track + '.10.rrf.P-3.lz4', kind='lz4')\n",
    "run_rrf_3.name = 'P-3'\n",
    "\n",
    "runs = [\n",
    "          run_bm25,\n",
    "          run_bm25_rm3,\n",
    "          run_rrf_1,\n",
    "          run_rrf_2,\n",
    "          run_rrf_3,\n",
    "        ]\n",
    "\n",
    "report = compare(\n",
    "    qrels=qrels,\n",
    "    runs=runs,\n",
    "    metrics=[\"precision@10\", \"ndcg@10\", \"bpref\", \"map\"],\n",
    "    max_p=0.05 / len(runs)\n",
    ")\n",
    "\n",
    "print(report)\n",
    "print(report.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the same fusion methods with different numbers of queries on four datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ranx import Qrels, Run, evaluate, compare\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# https://ir-datasets.com/nyt.html  \n",
    "qrels = Qrels.from_ir_datasets(\"nyt/trec-core-2017\")\n",
    "title = 'Core17'\n",
    "plot_path = \"../figures/delta_ndcg_core17_rrf_queries.pdf\"\n",
    "track = 'core17'\n",
    "num_topics = 50\n",
    "\n",
    "# https://ir-datasets.com/wapo.html \n",
    "# qrels = Qrels.from_ir_datasets(\"wapo/v2/trec-core-2018\")\n",
    "# title = 'Core18'\n",
    "# plot_path = \"../figures/delta_ndcg_core18_rrf_queries.pdf\"\n",
    "# track = 'core18'\n",
    "# num_topics = 50\n",
    "\n",
    "# https://ir-datasets.com/disks45.html \n",
    "# qrels = Qrels.from_ir_datasets(\"disks45/nocr/trec-robust-2004\")\n",
    "# title = 'Robust04'\n",
    "# plot_path = \"../figures/delta_ndcg_robust04_rrf_queries.pdf\"\n",
    "# track = 'robust04'\n",
    "# num_topics = 250\n",
    "\n",
    "# https://ir-datasets.com/aquaint.html\n",
    "# qrels = Qrels.from_ir_datasets(\"aquaint/trec-robust-2005\")\n",
    "# title = 'Robust05'\n",
    "# plot_path = \"../figures/delta_ndcg_robust05_rrf_queries.pdf\"\n",
    "# track = 'robust05'\n",
    "# num_topics = 50\n",
    "\n",
    "baseline = Run.from_file('runs/baseline/' + track + '.BM25.lz4', kind='lz4')\n",
    "baseline.name = 'Title'\n",
    "\n",
    "run_rrf_3 = Run.from_file('runs/gpt-4o/' + track + '.3.rrf.P-2.lz4', kind='lz4')\n",
    "run_rrf_3.name = 'RRF (3 queries)'\n",
    "\n",
    "run_rrf_5 = Run.from_file('runs/gpt-4o/' + track + '.5.rrf.P-2.lz4', kind='lz4')\n",
    "run_rrf_5.name = 'RRF (5 queries)'\n",
    "\n",
    "run_rrf_10 = Run.from_file('runs/gpt-4o/' + track + '.10.rrf.P-2.lz4', kind='lz4')\n",
    "run_rrf_10.name = 'RRF (10 queries)'\n",
    "\n",
    "run_rrf_100 = Run.from_file('runs/gpt-4o/' + track + '.100.rrf.P-2.lz4', kind='lz4')\n",
    "run_rrf_100.name = 'RRF (100 queries)'\n",
    "\n",
    "runs = [baseline, \n",
    "        run_rrf_3, \n",
    "        run_rrf_5, \n",
    "        run_rrf_10, \n",
    "        run_rrf_100]\n",
    "\n",
    "report = compare(\n",
    "    qrels=qrels,\n",
    "    runs=runs, \n",
    "    metrics=[\"ndcg\", \"map\", \"precision@10\", \"bpref\"],\n",
    "    max_p=0.05 / len(runs)\n",
    ")\n",
    "\n",
    "print(report.to_latex())\n",
    "\n",
    "measure = 'ndcg'\n",
    "\n",
    "delta_rrf_3 = pd.DataFrame.from_dict(run_rrf_3.scores) - pd.DataFrame.from_dict(baseline.scores) \n",
    "d_rrf_3 = delta_rrf_3[measure].sort_values(ascending=False).reset_index()[measure]\n",
    "\n",
    "delta_rrf_5 = pd.DataFrame.from_dict(run_rrf_5.scores) - pd.DataFrame.from_dict(baseline.scores) \n",
    "d_rrf_5 = delta_rrf_5[measure].sort_values(ascending=False).reset_index()[measure]\n",
    "\n",
    "delta_rrf_10 = pd.DataFrame.from_dict(run_rrf_10.scores) - pd.DataFrame.from_dict(baseline.scores) \n",
    "d_rrf_10 = delta_rrf_10[measure].sort_values(ascending=False).reset_index()[measure]\n",
    "\n",
    "delta_rrf_100 = pd.DataFrame.from_dict(run_rrf_100.scores) - pd.DataFrame.from_dict(baseline.scores) \n",
    "d_rrf_100 = delta_rrf_100[measure].sort_values(ascending=False).reset_index()[measure]\n",
    "\n",
    "deltas = {\n",
    "          '3 queries': d_rrf_3, \n",
    "          '5 queries': d_rrf_5, \n",
    "          '10 queries': d_rrf_10, \n",
    "          '100 queries': d_rrf_100, \n",
    "          }\n",
    "\n",
    "\n",
    "ax = pd.DataFrame.from_dict(deltas).plot(xlabel='Topics', \n",
    "                                                ylabel='$\\Delta$ nDCG', \n",
    "                                                title=title,\n",
    "                                                figsize=(3,3))\n",
    "ax.hlines(y=0, xmin=0, xmax=num_topics, colors='grey', linestyles='--', lw=2)\n",
    "plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False)\n",
    "plt.savefig(plot_path, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
